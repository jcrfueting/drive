\documentclass[a4paper]{article}
    \usepackage{amsmath, amssymb}
    \usepackage{graphicx}

\begin{document}
\SweaveOpts{concordance=TRUE, echo=FALSE}

\author{Janos C. R. F\"uting}
\title{Extreme Value Analysis \\ Fall 2023 \\ Assignment 2}

\maketitle

<<setup>>=
set.seed(10)
xnm <- rexp(2000)

# reusing dev_ci function from assignment 1
dev_ci <- function(plike, conf, optim_res, par_idx=1,
                   lower, upper, d=1){
    max_like=optim_res$value
    max_par=optim_res$par[par_idx]

    like_dist=0.5*qchisq(conf, d)

    loss_fun=\(x) ((max_like-plike(x))-like_dist)^2

    ci_lower=optimise(loss_fun, c(lower, max_par))$minimum

    ci_upper=optimise(loss_fun, c(max_par, upper))$minimum

    return(c(ci_lower, ci_upper))
}
@

\section*{Problem 1}

<<CI function definitions>>=
asymCI <- function(coverage=.95, prob=NULL, bsize, obs){
    block_max <- apply(matrix(obs, ncol=bsize, byrow=TRUE), 1, max)

    prob <- 1-1/(NROW(obs)/bsize)

    model <- mev::fit.gev(block_max)

    phi <- \(x, q=prob) mev::qgev(q, loc=x[1], scale=x[2], shape=x[3])

    V <- model$vcov

    theta_0 <- model$estimate

    nabla_phi <- attr(numericDeriv(quote(phi(theta_0)), c("theta_0")),
                      "gradient")

    V_phi <- tcrossprod(tcrossprod(nabla_phi, V), nabla_phi)

    ci <- phi(theta_0)+c(-1, 1)*qnorm(1-(1-coverage)/2,
                                      sd=sqrt(diag(V_phi)))

    return(ci)
}

profCI <- function(coverage=.95, prob=.95, bsize, obs){
    block_max <- apply(matrix(obs, ncol=bsize, byrow=TRUE), 1, max)

    prob <- 1-1/(NROW(obs)/bsize)

    model <- mev::fit.gev(block_max)

    # gev.pll expects *tail* probability, so have to convert
    pll <- \(x) mev::gev.pll(x, param="quant", p=1-prob,
                             dat=block_max, plot=FALSE)$pll

    optres <- list("value"=-model$nllh,
                    "par"=mev::qgev(prob,
                                    loc=model$estimate["loc"],
                                    scale=model$estimate["scale"],
                                    shape=model$estimate["shape"]))

    ci <- dev_ci(pll, coverage, optres,
                 lower=0, upper=10*max(block_max))

    return(ci)
}
@

<<results=tex>>=
ci_mat  <- t(vapply(c(20,  50, 100), \(x){
    c(asymCI(bsize=x, obs=xnm), profCI(bsize=x, obs=xnm))
}, numeric(4)))

dimnames(ci_mat) <- list(c("b=20", "b=50", "b=100"),
                         c("asym_l","asym_u","prof_l","prof_u"))

print(xtable::xtable(ci_mat, caption="Lower and Upper bounds of confidence intervals by method and block size b"))
@

Firstly, note that block size is inversely related to the sample size available for fitting our distribution.
Hence it is not surprising that our confidence intervals get much wider with increasing block size, as this means much more uncertainty in our estimates. Though of course our certainty in that our GEV model is correct increases as the blocksize increases. I.e. we are more certain that the distribution comes from a GEV but less certain about the paricular parameter combination it could have come from.

\section*{Problem 2}
<<simulation function>>=
ci_eval <- function(rdist, qdist, ci_list, bsize,
                    ntrial=1e4, nsample=2000){


    prob <- 1-1/(nsample/bsize)

    # random ntrial*nsample matrix
    sim_mat <- matrix(rdist(ntrial*nsample),
                      byrow=TRUE, ncol=nsample)

    # setting up parallelisation & calculating CIs
    # TODO: implement load balancing with parLapplyLB
    cl <- parallel::makeCluster(min(20, parallel::detectCores()))

    sim_cis <- lapply(ci_list, \(ci){
        parallel::clusterExport(cl=cl,
                                varlist=c("bsize", "ci", "dev_ci"),
                                envir=environment())
        t(parallel::parApply(cl=cl, sim_mat, 1, \(r){
            # sometimes our estimated xi < -.5 and we dont get a
            # variance matrix from mev so we have to handle that error
            tryCatch({ci(obs=r, bsize=bsize)}, error=\(e) c(NA, NA))
        }))
    })

    # coverage

    true_q <- qdist(p=1-1/nsample)

    coverage <- lapply(sim_cis, \(cimat){
        mean((cimat[,1] <= true_q) & (true_q <= cimat[,2]), na.rm=T)
    })

    # length

    ci_length <- lapply(sim_cis, \(cimat){
        mean(cimat[,2]-cimat[,1], na.rm=T)
    })

    return(unlist(c(coverage, ci_length)))
}

pretty_print <- function(eval_list,
                         b=c(20, 50, 100),
                         ci=c("asym", "prof"),
                         ...){

    result_mat <- do.call(rbind, eval_list)

    dimnames(result_mat) <- list(paste0("b=", b),
                                 paste0(ci,
                                        rep(c(" coverage"," size"),
                                            each=2)))

    print(xtable::xtable(result_mat, ...))
}

NTRIAL <- 1e2
@


<<i, results=tex>>=
# caching results so Sweaving doesn't take too long
try({
    eval_i <- readRDS("assignment_2_p2_i.RDS")
}, silent=TRUE)

if(!exists("eval_i")){
    eval_i <- lapply(c(20, 50, 100), function(x){
        ci_eval(rexp,
                qexp,
                list(asymCI, profCI), bsize=x, ntrial=NTRIAL)
    })
    saveRDS(eval_i, "assignment_2_p2_i.RDS")
}

pretty_print(eval_i,
             caption="Comparison of CI methods by coverage and size,
             depending on block size. Data from Exponential with scale
             1, i.e. Weibull with scale 1 and shape 1.")
@


<<ii, results=tex>>=# caching results so Sweaving doesn't take too long
try({
    eval_ii <- readRDS("assignment_2_p2_ii.RDS")
}, silent=TRUE)

if(!exists("eval_ii")){
    eval_ii <- lapply(c(20, 50, 100), function(x){
        ci_eval(\(n) rweibull(n, scale=1, shape=.5),
                \(p) qweibull(p, scale=1, shape=.5),
                list(asymCI, profCI), bsize=x, ntrial=NTRIAL)
    })
    saveRDS(eval_ii, "assignment_2_p2_ii.RDS")
}

pretty_print(eval_ii,
             caption="Comparison of CI methods by coverage and size,
             depending on block size. Data from Weibull with scale
             1 and shape .5.")
@


<<iii, results=tex>>=# caching results so Sweaving doesn't take too long
try({
    eval_iii <- readRDS("assignment_2_p2_iii.RDS")
}, silent=TRUE)

if(!exists("eval_iii")){
    eval_iii <- lapply(c(20, 50, 100), function(x){
        ci_eval(\(n) rweibull(n, scale=1, shape=5),
                \(p) qweibull(p, scale=1, shape=5),
                list(asymCI, profCI), bsize=x, ntrial=NTRIAL)
    })
    saveRDS(eval_iii, "assignment_2_p2_iii.RDS")
}

pretty_print(eval_iii,
             caption="Comparison of CI methods by coverage and size,
             depending on block size. Data from Weibull with scale
             1 and shape 5.")
@

What we can see from the tables

\end{document}
